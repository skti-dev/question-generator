import os
import sys
from dotenv import load_dotenv

# Carregar variÃ¡veis de ambiente
load_dotenv()

# Adicionar path para imports
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
  from pipeline import pipeline, get_subjects, get_codes_for_subject
  from models.schemas import DifficultyLevel, QuestionType
  
  def test_basic_functionality():
    """Testa funcionalidades bÃ¡sicas da pipeline"""
    print("ğŸ§ª INICIANDO TESTES DA PIPELINE")
    print("=" * 50)
    
    # Teste 1: Verificar carregamento de dados
    print("\n1. ğŸ“Š Testando carregamento de dados BNCC...")
    subjects = get_subjects()
    print(f"   âœ… MatÃ©rias encontradas: {subjects}")
    
    if not subjects:
      print("   âŒ ERRO: Nenhuma matÃ©ria encontrada!")
      return False
    
    # Teste 2: Verificar cÃ³digos por matÃ©ria
    print("\n2. ğŸ“‹ Testando cÃ³digos por matÃ©ria...")
    for subject in subjects:
      codes = get_codes_for_subject(subject)
      print(f"   ğŸ“– {subject}: {len(codes)} cÃ³digos")
      if codes:
        print(f"      Exemplo: {codes[0]['codigo']} - {codes[0]['objeto_conhecimento'][:50]}...")
    
    # Teste 3: Gerar uma questÃ£o simples
    print("\n3. ğŸ¯ Testando geraÃ§Ã£o de questÃ£o...")
    
    # Pegar primeiro cÃ³digo de matemÃ¡tica
    math_codes = get_codes_for_subject("MatemÃ¡tica")
    if not math_codes:
      print("   âŒ ERRO: Nenhum cÃ³digo de matemÃ¡tica encontrado!")
      return False
    
    test_code = math_codes[0]["codigo"]
    print(f"   ğŸ§® Testando com cÃ³digo: {test_code}")
    
    try:
      # Gerar uma questÃ£o de mÃºltipla escolha fÃ¡cil
      from pipeline import generate_questions
      
      batches = generate_questions(
        codes=[test_code],
        easy_count=1,
        medium_count=0,
        hard_count=0,
        multiple_choice_ratio=1.0
      )
      
      if batches and len(batches) > 0:
        batch = batches[0]
        print(f"   âœ… QuestÃµes geradas: {batch.total_generated}")
        print(f"   âœ… QuestÃµes aprovadas: {batch.total_approved}")
        
        if batch.questions:
          question = batch.questions[0].question
          validation = batch.questions[0].validation
          
          print(f"\n   ğŸ“ EXEMPLO DE QUESTÃƒO GERADA:")
          print(f"   {'-' * 40}")
          print(f"   {question.format_question()}")
          print(f"   {'-' * 40}")
          print(f"   ğŸ” ValidaÃ§Ã£o - Alinhada: {validation.is_aligned}")
          print(f"   ğŸ” ConfianÃ§a: {validation.confidence_score:.2f}")
          print(f"   ğŸ” Feedback: {validation.feedback}")
        
        return True
      else:
        print("   âŒ ERRO: Nenhuma questÃ£o foi gerada!")
        return False
        
    except Exception as e:
      print(f"   âŒ ERRO na geraÃ§Ã£o: {str(e)}")
      import traceback
      traceback.print_exc()
      return False
  
  def test_cache_functionality():
    """Testa funcionalidade do cache"""
    print("\n4. ğŸ’¾ Testando sistema de cache...")
    
    try:
      stats = pipeline.get_cache_stats()
      print(f"   âœ… Cache inicializado: {stats['total_entries']} entradas")
      return True
    except Exception as e:
      print(f"   âŒ ERRO no cache: {str(e)}")
      return False
  
  def run_all_tests():
    """Executa todos os testes"""
    print("ğŸš€ INICIANDO BATERIA DE TESTES COMPLETA")
    print("=" * 60)
    
    tests = [
      ("Funcionalidade BÃ¡sica", test_basic_functionality),
      ("Sistema de Cache", test_cache_functionality)
    ]
    
    results = []
    for test_name, test_func in tests:
      try:
        result = test_func()
        results.append((test_name, result))
      except Exception as e:
        print(f"\nâŒ ERRO CRÃTICO em {test_name}: {e}")
        results.append((test_name, False))
    
    # Resumo dos resultados
    print("\n" + "=" * 60)
    print("ğŸ“Š RESUMO DOS TESTES")
    print("=" * 60)
    
    passed = 0
    for test_name, result in results:
      status = "âœ… PASSOU" if result else "âŒ FALHOU"
      print(f"   {test_name}: {status}")
      if result:
        passed += 1
    
    print(f"\nğŸ¯ RESULTADO FINAL: {passed}/{len(tests)} testes passaram")
    
    if passed == len(tests):
      print("ğŸ‰ TODOS OS TESTES PASSARAM! Pipeline estÃ¡ funcionando corretamente.")
    else:
      print("âš ï¸  Alguns testes falharam. Verifique os erros acima.")
    
    return passed == len(tests)

  if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)

except ImportError as e:
  print(f"âŒ ERRO DE IMPORTAÃ‡ÃƒO: {e}")
  print("Verifique se todos os arquivos foram criados corretamente.")
  sys.exit(1)
except Exception as e:
  print(f"âŒ ERRO GERAL: {e}")
  import traceback
  traceback.print_exc()
  sys.exit(1)